{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importing essential library \n",
    "import numpy as np \n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renamed the files to make it more accessible and intuitive.\n",
    "#reading csv files into pd dataframes for manipulation and data wrangling\n",
    "cardholder_acc = pd.read_csv('../csvs_datathon/accy_dim.csv')\n",
    "statement_data = pd.read_csv('../csvs_datathon/statement_fact.csv')\n",
    "transaction_data = pd.read_csv('../csvs_datathon/transaction_fact.csv')\n",
    "wrld_transaction_data = pd.read_csv('../csvs_datathon/wrld_stor_tran_fact.csv')\n",
    "customer_id = pd.read_csv('../csvs_datathon/syf_id.csv')\n",
    "acc_lvl_features = pd.read_csv('../csvs_datathon/rams_batch_cur.csv')\n",
    "fraud_claim_case = pd.read_csv('../csvs_datathon/fraud_claim_case.csv')\n",
    "fraud_claim_tran = pd.read_csv('../csvs_datathon/fraud_claim_tran.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data_sales = transaction_data[(transaction_data['transaction_type'] != 'PAYMENT')]\n",
    "wrld_transaction_data_sales = wrld_transaction_data[(wrld_transaction_data['transaction_type'] != \"PAYMENT\")] \n",
    "\n",
    "transaction_data_sales['transaction_date'] = pd.to_datetime(transaction_data_sales['transaction_date'])\n",
    "transaction_data_salesf = transaction_data_sales[(transaction_data_sales['transaction_date'] >= \"2024-08-01\") & (transaction_data_sales['transaction_date'] <= \"2025-03-31\")] \n",
    "\n",
    "wrld_transaction_data_sales['transaction_date'] = pd.to_datetime(wrld_transaction_data_sales['transaction_date'])\n",
    "wrld_transaction_data_salesf = wrld_transaction_data_sales[(wrld_transaction_data_sales['transaction_date'] >= \"2024-08-01\") & (wrld_transaction_data_sales['transaction_date'] <= \"2025-03-31\")]\n",
    "\n",
    "\n",
    "total_sales_customer1 = transaction_data_sales.groupby('current_account_nbr')['transaction_amt'].sum().reset_index()\n",
    "total_sales_customer1.rename(columns = {'transaction_amt' : 'total spent'})\n",
    "\n",
    "total_sales_customer2 = wrld_transaction_data_sales.groupby('current_account_nbr')['transaction_amt'].sum().reset_index() \n",
    "total_sales_customer2.rename(columns = {'transaction_amt' : 'total spent'})\n",
    "\n",
    "f_sales1 = transaction_data_salesf.groupby('current_account_nbr')['transaction_amt'].sum().reset_index()\n",
    "f_sales2 = wrld_transaction_data_salesf.groupby('current_account_nbr')['transaction_amt'].sum().reset_index()\n",
    "\n",
    "all_transactions = pd.DataFrame(columns = ['current account nbr', 'total spent'])\n",
    "acc_nbrs = total_sales_customer1['current_account_nbr'].to_list() + total_sales_customer2['current_account_nbr'].to_list()\n",
    "acc_total_spent = total_sales_customer1['transaction_amt'].to_list() + total_sales_customer2['transaction_amt'].to_list()\n",
    "\n",
    "\n",
    "all_transactions['current_account_nbr'] = acc_nbrs\n",
    "all_transactions['total spent'] = acc_total_spent\n",
    "\n",
    "all_transactions['total spent per month'] = all_transactions['total spent'] / 12\n",
    "all_transactions['total spent per quarter'] = all_transactions['total spent'] / 3\n",
    "all_transactions\n",
    "\n",
    "f_sales1.rename(columns = {'transaction_amt': 'total spent last 8 months'}, inplace = True)\n",
    "f_sales2.rename(columns = {'transaction_amt': 'total spent last 8 months'}, inplace = True)\n",
    "all_transactions = pd.merge(all_transactions, f_sales1, on = 'current_account_nbr', how = 'left')\n",
    "all_transactions = pd.merge(all_transactions, f_sales2, on = 'current_account_nbr', how = 'left', suffixes = ('', '_wrld'))\n",
    "all_transactions['total spent last 8 months'] = all_transactions[['total spent last 8 months', 'total spent last 8 months_wrld']].sum(axis=1)\n",
    "all_transactions.drop(columns=['total spent last 8 months_wrld'], inplace = True)\n",
    "all_transactions['total spent last 8 months'].fillna(0, inplace = True)\n",
    "\n",
    "acc_lvl_features = acc_lvl_features.rename(columns = {'cu_account_nbr' : 'current_account_nbr'})\n",
    "avg_util_3_months = acc_lvl_features.groupby('current_account_nbr')['ca_avg_utilz_lst_3_mnths'].mean().reset_index()\n",
    "all_transactions = pd.merge(all_transactions, avg_util_3_months, on = 'current_account_nbr', how = 'left')\n",
    "all_transactions['ca_avg_utilz_lst_3_mnths'].fillna(0, inplace = True)\n",
    "\n",
    "acc_lvl_features['difference_behav_score'] = acc_lvl_features['rb_new_bhv_scr'] - acc_lvl_features['cu_bhv_scr']\n",
    "diff_behav_scr = acc_lvl_features.groupby('current_account_nbr')['difference_behav_score'].mean().reset_index()\n",
    "all_transactions = pd.merge(all_transactions, diff_behav_scr, on = 'current_account_nbr', how = 'left')\n",
    "all_transactions['difference_behav_score'].fillna(0, inplace = True)\n",
    "all_transactions = all_transactions.rename(columns = {'total spent' : 'total spent year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
    "x = all_transactions[['total spent year', 'total spent per month', 'total spent last 8 months', 'ca_avg_utilz_lst_3_mnths', 'difference_behav_score']]\n",
    "y = all_transactions[['total spent per quarter']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.20, random_state = 50)\n",
    "xgboost_model = XGBRegressor(n_estimators = 200, learning_rate = 0.1)\n",
    "xgboost_model.fit(X_train, Y_train)\n",
    "predictions = xgboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = r2_score(Y_test, predictions)\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@rithpansanga/optimizing-xgboost-a-guide-to-hyperparameter-tuning-77b6e48e289d\n",
    "param_dist = {\n",
    "    'max_depth': stats.randint(3, 10),\n",
    "    'learning_rate': stats.uniform(0.01, 0.1),\n",
    "    'subsample': stats.uniform(0.5, 0.5),\n",
    "    'n_estimators':stats.randint(50, 200)\n",
    "}\n",
    "random_search = RandomizedSearchCV(xgboost_model, param_distributions = param_dist, n_iter = 30, cv = 5, scoring = 'accuracy')\n",
    "random_search.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(x, y, test_size = 0.20, random_state = 50)\n",
    "xgboost_model = XGBRegressor(n_estimators = 50, learning_rate = 0.08866319931044156, max_depth = 9, subsample = 0.8036166601891328)\n",
    "xgboost_model.fit(X_train2, Y_train2)\n",
    "predictions2 = xgboost_model.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared2 = r2_score(Y_test2, predictions2)\n",
    "r_squared2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse2 = np.sqrt(mean_squared_error(Y_test2, predictions2))\n",
    "rmse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_y2 = Y_test2.max() - Y_test2.min()\n",
    "n_rmse2 = rmse2 / range_y2\n",
    "n_rmse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(Y_test2, predictions2)\n",
    "mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyons kernel",
   "language": "python",
   "name": "lyons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
